{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfuQLIOeejXmx5z4h0OcPQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nada-Abidii/AI-for-FinTech/blob/main/ocr_pie_chart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####1. Installations"
      ],
      "metadata": {
        "id": "VCmJt9ojf9-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjeLQxPtcpMP"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "!pip install pytesseract\n",
        "!apt-get install tesseract-ocr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 2. Importations"
      ],
      "metadata": {
        "id": "75FBa3Z5gCVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "import pytesseract\n",
        "from PIL import Image, ImageDraw, ImageOps, ImageEnhance"
      ],
      "metadata": {
        "id": "JhXa-dRnc1-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Image Preparation and Preprocessing\n"
      ],
      "metadata": {
        "id": "VV1ZhAG8gLAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Roboflow API key and model info\n",
        "api_key = \"**********\"\n",
        "workspace_id = \"*************\"\n",
        "project_id = \"************\"\n",
        "version_number = 3\n",
        "\n",
        "# Load the model\n",
        "rf = Roboflow(api_key=api_key)\n",
        "project = rf.workspace(workspace_id).project(project_id)\n",
        "model = project.version(version_number).model\n",
        "\n",
        "# Function to draw boxes around detections\n",
        "def draw_boxes(image, detections):\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    for detection in detections[\"predictions\"]:\n",
        "        box = [\n",
        "            detection[\"x\"] - detection[\"width\"] / 2,\n",
        "            detection[\"y\"] - detection[\"height\"] / 2,\n",
        "            detection[\"x\"] + detection[\"width\"] / 2,\n",
        "            detection[\"y\"] + detection[\"height\"] / 2,\n",
        "        ]\n",
        "        label = detection[\"class\"]\n",
        "        draw.rectangle(box, outline=\"red\", width=2)\n",
        "        draw.text((box[0], box[1]), label, fill=\"red\")\n",
        "    return image"
      ],
      "metadata": {
        "id": "Lf1Sy0y5fcJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Text Extraction with OCR\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6SfACc0vgZOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract text from specific regions of the image using OCR\n",
        "def extract_text_from_image(image, region=None):\n",
        "    if region:\n",
        "        cropped_image = image.crop(region)\n",
        "    else:\n",
        "        cropped_image = image\n",
        "    text = pytesseract.image_to_string(cropped_image, config='--psm 6') # This line uses the imported library\n",
        "    return text\n",
        "\n",
        "# Extract title from the top of the chart\n",
        "def extract_title(image):\n",
        "    width, height = image.size\n",
        "    title_region = (0, 0, width, height * 0.2)  # Top 20% of the image\n",
        "    title_text = extract_text_from_image(image, title_region)\n",
        "    return title_text.strip()\n",
        "\n",
        "# Extract classes from the pie chart\n",
        "def extract_classes(image):\n",
        "    width, height = image.size\n",
        "    region = (0.68 * width, 0, width, height)\n",
        "    text = extract_text_from_image(image, region).strip()\n",
        "    return text\n",
        "\n",
        "# Process the pie chart\n",
        "detection = model.predict('Pie-Chart-3.png', confidence=40, overlap=30).json()\n",
        "image3 = Image.open('Pie-Chart-3.png').convert(\"RGB\")\n",
        "image3 = draw_boxes(image3, detection)\n",
        "image3.save('annotated3.png')\n",
        "\n",
        "# Assuming crop_and_save is defined elsewhere\n",
        "# If not, you'll need to define it to avoid further errors\n",
        "# For example:\n",
        "def crop_and_save(image, detection):\n",
        "    # Replace this with your actual logic to crop and save images\n",
        "    return [image]  # This is a placeholder, replace with your actual implementation\n",
        "\n",
        "cropped_images3 = crop_and_save(image3, detection)\n",
        "for j, cropped_image3 in enumerate(cropped_images3):\n",
        "    title = extract_title(cropped_image3)\n",
        "    classes = extract_classes(cropped_image3)\n",
        "    print(f'Title for chart box {j}: {title}')\n",
        "    print(f'Classes for chart box {j}: {classes}')"
      ],
      "metadata": {
        "id": "gPs9HSDqdxBd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}